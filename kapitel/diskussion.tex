\documentclass[../rapport_MVEX01-11-05]{subfiles}
\begin{document}
Med de metoder som beskrivits nås alltså en träffsäkerhet på 91.4\,\%
för våra tio statiska gester. I ett antal stycken framöver diskuteras
vad som skulle kunna göras för att ytterligare förbättra
träffsäkerheten, utvidga programmets funktionalitet eller på övrigt
sätt gå vidare från resultatet.

\section{Hudigenkänning}
De sannolikhetsfördelningar som använts för att skilja hud från annat
har fungerat tillräckligt bra för att kunna skilja ut handen i en
relativt kontrollerad miljö. Bättre resultat skulle dock kunna uppnås
med bättre sannolikhetsfördelningar. Det man främst skulle kunna göra
är att använda k-klustring, d.v.s.~linjärkombinationer av flera
sannolikhetsfördelningar, även för ickehud. Bättre fördelningar skulle
antagligen även fås med en större datamängd, alltså fler
exempelbilder.

Man skulle också kunna använda någon annan klassificerare, såsom \knn,
vid skapandet av vår SCM. En svårighet med det är att det skulle
kräva kassering av data för att få lika stora prototypmängder,
eller viktning av datapunkterna.

Efter det statistiska urvalet skulle man kunna redigera direkt i
hudfärgskartan för att få ett bättre resultat. Detta är dock väldigt
tidskrävande.

\section{Handidentifiering}

\section{\knn}
Något som kan göras för att förbättra \knn-metodens träffsäkerhet är först och
främst att utöka prototypmängden till fler punkter per gest. En annan möjlig
förbättring skulle vara att inspektera de bilder som faktiskt ligger bakom
punkten i egenskapsrummet. Om den uppenbart är felaktig, och kanske hade varit
svår att tolka som rätt gest även för en människa, kan den med fördel tas bort.
Slarvigt utförda gester kommer då mindre sannolikt att
klassificeras rätt.\notes{om alls? thresholding?!}

\section{Features}
Inre av handen (linjer etc)

Kurvatur (fingertoppar, avstånd däremellan)

\section{Realtid}
\section{Tillämpningar}
Alfabetsigenkänning, sten-sax-påse

\section{Dynamiska gester}





\end{document}
