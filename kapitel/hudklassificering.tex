\documentclass[../rapport_MVEX01-11-05]{subfiles}
\begin{document}

\subsection{Klassificering av hudfärg och urskiljning av händer}\label{sec:hudklassificering}

\subsubsection{Färgrymder}

En färg kan matematiskt beskrivas som en vektor i ett färgrum, vars
basvektorer är grundfärger i färsystemet. För att kunna representera alla färger
behöver man ett tredimensionellt färgrum, men i vissa situationer kan
det räcka --- kanske till och med vara fördelaktigt --- med ett
tvådimensionellt färgrum \cite{Kakumanu07}.

Vilken färgrymd som är bäst för just hudklassificering beror på
situation. RGB-liknande färgrymder har använts av bland annat
\citeasnoun{Lockton02} och \citeasnoun{Sebe04}, och ter sig lämplig
eftersom det är denna färgrymd som används i datorer. Perceptuella
färgrymder som separerar kulör och styrka, till exempel HSL, har inte
rönt någon större framgång eftersom de är prestandamässigt olämpliga
att använda i realtidstillämpningar.

Ortogonala färgrymder har däremot nått stor användning för
hudklassificering \cite{Hsu02,Elmezain08,Hassanpour08} eftersom de
både separerar färg från ljusstyrka och är linjärtransformationer av
RGB och därmed prestandamässigt lämpliga för realtidsapplikationer.
En ortogonal färgrymd som har stor utbredning och som även visat
sig vara mycket bra \cite{Kakumanu07} är $YC_bC_r$.

\subsubsection[Färgrymden $\mathrm{YC_bC_r}$]{Färgrymden $\mathbf{YC_bC_r}$}

$YC_bC_r$-rymden är ett försök att ortogonalisera RGB-rymden genom en
linjärtransformation, vilken resulterar i en basvektor som
representerar ljusstyrka ($Y$) och två som representerar ''chroma''
(färg), $C_b$ och $C_r$. Enligt den standard International
Telecommunication Union publicerat \cite{ITU-BT601} ges
linjärtransformationen av

\begin{equation*}
  \label{eq:farg:ycbcr}
  \begin{gathered}
  Y   = 16  + ( 65.481R + 128.553G + 24.966B)\\
  C_b = 128 + (-37.797R - 74.203G  + 112.0B )\\
  C_r = 128 + (112.0R   - 93.786G  - 18.214B)
  \end{gathered}
\end{equation*}

där $R$, $G$, och $B$ är värden mellan $0$ och $255$ som representerar
färgens värde i RGB-rymden.

\subsubsection{Sannolikhetsfördelning för hudfärg}

För att skilja bildpunkter med hud från bakgrunden, vilket är ett
centralt problem inom gestigenkänning, kan flera olika statistiska
metoder
appliceras. Man har till exempel gjort försök med skogar av
slumpmässiga träd
\cite{Khan10}, Bayesiska nätverk \cite{Sebe04}, generativa modeller
\cite{Kruppa02}
och luddig aritmetik \cite{Shang10} --- en större undersökning av metoder
för huddetektion gjordes av \citeasnoun{Kakumanu07}.

En enklare metod som nått relativt stor framgång är den som baseras på
Gaussian Mixture Models \cite{Elmezain08,Hassanpour08}, det vill säga
en modell där bildpunktens färg antas bero stokastiskt på om
bildpunkten föreställer hud eller inte.

Färgen antas då vara en multivariat normalfördelad
stokastisk variabel, där fördelningens parametrar alltså beror på om
pixeln motsvarar hud eller inte. För att täcka olika hudfärger kan en
uppsättning olika
fördelningar för hudfärger användas, där en total
sannolikhetsfördelning sedan är en linjärkombination av dessa. Detsamma
kan göras med sannolikhetsfördelningen för bildpunkter som inte
innehåller hud.

För att bestämma väntevärdesvektorn och kovariansmatrisen i en
uppskattad normalfördelning krävs ett
antal datapunkter, med vilkas hjälp parametrarna kan skattas med maximum
likelihood-metoden.

Fördelningen gess allmänt av
\begin{equation*}
  p(x)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}e^{-(x-\mu)^T\Sigma^{-1}(x-\mu)/2}
\end{equation*}
med kovariansmatris $\Sigma$ och väntevärde $\mu$.
Givet $N$ datapunkter $x_i,\:1\leq i\leq N$ ges den logaritmerade
sannolikheten $l(\mu,\Sigma|x_1,{\ldots} ,x_N)$ av
\begin{equation*}
  \begin{aligned}
  l(\mu,\Sigma|x_1,...,x_N) = &-\frac{Nd}{2}\log(2\pi)-\frac{N}{2}\log|\Sigma|\\
                              &-\sum_{i=1}^N\frac{(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)}{2}.
  \end{aligned}
\end{equation*}

Vi kan därefter beräkna derivatan med avseende på $\mu$,
\begin{equation*}
  \frac{\partial l}{\partial \mu}=\sum_{i=1}^N(x_i-\mu)^T\Sigma^{-1},
\end{equation*}
samt derivatan med avseende på $\Sigma^{-1}$,
\begin{equation*}
  \frac{\partial l}{\partial \Sigma^{-1}}=\frac{N}{2}\Sigma
  -\sum_{i=1}^N\frac{(x_i-\mu)(x_i-\mu)^T}{2}.
\end{equation*}

Sätter man dem i tur och ordning till noll fås uppskattningarna
$\hat\mu$ och $\hat\Sigma$:
\notes{Hur då? Det är \emph{inte} uppenbart!}
\begin{gather*}
  \hat\mu    =\frac{1}{N}-\sum_{i=1}^Nx_i\\
  \hat\Sigma =\frac{1}{N-1}\sum_{i=1}^N(x_i-\hat\mu)(x_i-\hat\mu)^T
\end{gather*}

För att ytterligare förbättra fördelningarna kan de antas vara
sammansatta av flera fördelningar. En iterativ metod för optimering av
sådana fördelningar beskrivs av \citeasnoun{Elmezain08}

För varje pixelfärg kan alltså sannolikheten för att färgen ska
förekomma då pixeln föreställer hud
respektive ickehud bestämmas. Med denna information kan man bestämma
att om kvoten 
\begin{multline*}
\frac{\Prob(\textrm{hud}|\textrm{färg})}{\Prob(\textrm{ickehud}|\textrm{färg})}=\\
=\frac{\Prob(\textrm{färg}|\textrm{hud})\Prob(\textrm{hud})}{\Prob(\textrm{färg})}
 \frac{\Prob(\textrm{färg}}{\Prob(\textrm{ickehud})\Prob(\textrm{ickehud}|\textrm{färg})}=\\
=\frac{\Prob(\textrm{färg}|\textrm{hud})\Prob(\textrm{hud})}{\Prob(\textrm{färg}|\textrm{ickehud})
 P(\textrm{ickehud})}
\end{multline*}
är större än ett, så sägs pixeln föreställa hud. 

\subsubsection{Morfologiska operationer}\label{sec:morph}

Morfologiska operationer kan användas för att modifiera ''objekt'' i
binära bilder, till exempel för att rensa bort brus eller för att
mjuka upp kanter. Det finns fyra grundläggande morfologiska
operationer: \emph{erosion}, \emph{dilatation}, \emph{öppning} och
\emph{stängning} \cite[ss.~25]{Rudemo09}.

Dessa definieras som operationer på mängder; specifikt mängden $A$
av alla svarta pixlar i bilden vi behandlar, dvs. alla pixlar som är
''avstängda'' och mängden $S$ som representerar ett strukturelement
som i någon mening förändrar hur operationen verkar på bilden.
Strukturelementet kan dessutom förflyttas så att dess referenspixel
ligger på plats $(i,j)$ i bilden --- kalla detta förflyttade
strukturelement för $S_{i,j}$.

\emph{Erosionen}, som eroderar bort delar av de svarta områdena genom
att endast behålla de pixlar vars ''omgivning'' (definierad av mängden
$S_{i,j}$) ligger helt i mängden $A$. Vad operationen egentligen gör är alltså
att skala av det yttersta lagret, randen, av mängden $A$. Erosion definieras enligt
\begin{equation*}
  A\ominus S = \{(i,j)\;:\;S_{i,j}\subseteq A\}.
\end{equation*}

Dess motsats, \emph{dilatation}, agerar som
en erosion på komplementet till $A$ och definieras enligt
\begin{equation*}
  A\oplus S = (A^C\ominus S)^C.
\end{equation*}

Dessa operationer är i sig inte särskilt användbara då de förändrar
arean av objekten i bilderna. Operationerna kan dock kombineras för
att skapa operationer som i någon mening endast 
''mjukar upp'' objekten i bilden utan att förändra deras area markant.
Eftersom erosion och dilatation är motsatser kan dessa appliceras i
följd för att behandla bilden och
sedan återställa den. Detta ger upphov till två nya operationer:
\emph{öppning} och \emph{stängning}.

En öppning är en erosion följd av en dilatation, enligt
\begin{equation*}
  \phi_S(A)=(A\ominus S)\oplus S'.
\end{equation*}

Detta resulterar i att svart ''brus'', dvs.~svarta områden som inte kan täckas av $S$, försvinner i
första steget varefter större svarta områdena utökas igen i det andra
steget. Operationen ''öppnar upp'' vita områden.

En stängning består av motsatt procedur, enligt
\begin{equation*}
  \Phi_S(A)=(A\oplus S)\ominus S',
\end{equation*}
och ger även motsatt resultat (svarta områden ''öppnas upp'').

De
båda operationerna använder utöver $A$ och $S$ även $S'$, vilket är
$S$ roterad 180\textdegree{} runt sin referenspixel.

\end{document} 
