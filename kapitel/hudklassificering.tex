\documentclass[../rapport_MVEX01-11-05]{subfiles}
\begin{document}

\subsection{Klassificering av hudfärg och urskiljning av händer}\label{sec:hudklassificering}

\subsubsection{Färgrymder}

Färg kan matematiskt beskrivas som vektorer i ett färgrum, vars
basvektorer är grundfärger i färsystemet. För att kunna representera alla färger
behöver man ett tredimensionellt färgrum, men i vissa situationer kan
det räcka --- kanske till och med vara fördelaktigt --- med ett
tvådimensionellt färgrum \cite{Kakumanu07}.

Vilken färgrymd som är bäst för just hudklassificering beror på
situation. RGB-liknande färgrymder har använts av bland annat
\citeasnoun{Lockton02} och \citeasnoun{Sebe04}, och ter sig lämplig
eftersom det är denna färgrymd som används i datorer. Perceptuella
färgrymder som separerar kulör och styrka, till exempel HSL, har inte
rönt någon större framgång eftersom de är prestandamässigt olämpliga
att använda i realtidstillämpningar.

Ortogonala färgrymder har däremot nått stor användning för
hudklassificering \cite{Hsu02,Elmezain08,Hassanpour08} eftersom de
både separerar färg från ljusstyrka och är linjärtransformationer av
RGB och därmed prestandamässigt lämpliga för realtidsapplikationer.
En ortogonal färgrymd som har stor utbredning och som även visat
sig vara mycket bra \cite{Kakumanu07} är $YC_bC_r$.

\subsubsection[Färgrymden $\mathrm{YC_bC_r}$]{Färgrymden $\mathbf{YC_bC_r}$}

$YC_bC_r$-rymden är ett försök att ortogonalisera RGB-rymden genom en
linjärtransformation, vilken resulterar i en basvektor som
representerar ljusstyrka ($Y$) och två som representerar ''chroma''
(färg), $C_b$ och $C_r$. Enligt den standard International
Telecommunication Union publicerat \cite{ITU-BT601} ges
linjärtransformationen av

\begin{equation*}
  \label{eq:farg:ycbcr}
  \begin{gathered}
  Y   = 16  + ( 65.481R + 128.553G + 24.966B)\\
  C_b = 128 + (-37.797R - 74.203G  + 112.0B )\\
  C_r = 128 + (112.0R   - 93.786G  - 18.214B)
  \end{gathered}
\end{equation*}

där $R$, $G$, och $B$ är värden mellan $0$ och $255$ som representerar
färgens värde i RGB-rymden.

\subsubsection{Sannolikhetsfördelning för hudfärg}

För att skilja bildpunkter med hud från bakgrunden, vilket är ett
centralt problem inom gestigenkänning, kan flera olika statistiska metoder
appliceras. Man har till exempel gjort försök med skogar av slumpmässiga träd
\cite{Khan10}, Bayesiska nätverk \cite{Sebe04}, generativa modeller \cite{Kruppa02}
och luddig aritmetik \cite{Shang10} --- en större undersökning av metoder
för huddetektion gjordes av \citeasnoun{Kakumanu07}.

En enklare metod som nått relativt stor framgång är den som baseras på
Gaussian Mixture Models \cite{Elmezain08,Hassanpour08}, det vill säga
en modell där bildpunktens färg antas bero stokastiskt på om bildpunkten
är hud eller inte.

Färgen antas då vara en multivariat normalfördelad
stokastisk variabel, där fördelningen beror på om bildpunkten innehåller hud
eller inte. För att täcka olika hudfärger kan en uppsättning olika
fördelningar för hudfärger användas, där en total
sannolikhetsfördelning sedan är en linjärkombination av dessa. Detsamma
kan göras med sannolikhetsfördelningen för bildpunkter som inte
innehåller hud. Det enklaste är dock att använda en enda fördelning för
hud, och anta att ''ickehudsfördelningen'' är konstant. Att använda flera
fördelningar för huden ger konsekvent liten varians för ickehud, vilket visats
av bland annat \citeasnoun{Elmezain08}.

För att bestämma väntevärdesvektorn och kovariansmatrisen i en
uppskattad normalfördelning krävs ett
antal datapunkter, med vilka vi kan uppskatta parametrarna med maximum
likelihood-metoden.

Den mulitvariata fördelningen ges, eftersom det är en normalfördelning, av
\begin{equation*}
  p(x)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}e^{-(x-\mu)^T\Sigma^{-1}(x-\mu)/2}
\end{equation*}
med kovariansmatris $\Sigma$ och väntevärde $\mu$.
Givet $N$ datapunkter $x_i,\:1\leq i\leq N$ ges den logaritmerade
sannolikheten $l(\mu,\Sigma|x_1,{\ldots} ,x_N)$ av
\begin{equation*}
  \begin{aligned}
  l(\mu,\Sigma|x_1,...,x_N) = &-\frac{Nd}{2}\log(2\pi)-\frac{N}{2}\log|\Sigma|\\
                              &-\sum_{i=1}^N\frac{(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)}{2}.
  \end{aligned}
\end{equation*}

Vi kan därefter beräkna derivatan med avseende på $\mu$,
\begin{equation*}
  \frac{\partial l}{\partial \mu}=\sum_{i=1}^N(x_i-\mu)^T\Sigma^{-1},
\end{equation*}
samt derivatan med avseende på $\Sigma^{-1}$,
\begin{equation*}
  \frac{\partial l}{\partial \Sigma^{-1}}=\frac{N}{2}\Sigma
  -\sum_{i=1}^N\frac{(x_i-\mu)(x_i-\mu)^T}{2}.
\end{equation*}

Sätter vi dem i tur och ordning till noll får vi uppskattningarna $\hat\mu$ och $\hat\Sigma$:
\notes{Hur då? Det är \emph{inte} uppenbart!}
\begin{gather*}
  \hat\mu    =\frac{1}{N}-\sum_{i=1}^Nx_i\\
  \hat\Sigma =\frac{1}{N-1}\sum_{i=1}^N(x_i-\hat\mu)(x_i-\hat\mu)^T
\end{gather*}

\citeasnoun{Elmezain08} studerade $18\;972$
bildpunkter med hud och $88\;320$ utan, och delade in dessa i fyra
hudfördelningar och en ickehudfördelning. De fyra hudfördelningarna
optimerades genom att varje bildpunkt sorterades till en
ursprungsfördelning, varefter parametrarna uppdaterades och alla
bildpunkter sorterades om efter de uppkomna fördelningarna --- detta gjordes
iterativt till konvergens.

\subsubsection{Hudfärgskarta}

För varje pixelfärg kan sannolikheten för att pixeln föreställer hud
respektive ickehud bestämmas med fördelningarna ovan, med en korrektion
för att det i allmänhet är troligare att pixlar är ickehud än hud. Detta
innebär att om kvoten
\begin{multline*}
\frac{\Prob(\textrm{hud}|\textrm{färg})}{\Prob(\textrm{ickehud}|\textrm{färg})}=\\
=\frac{\Prob(\textrm{färg}|\textrm{hud})\Prob(\textrm{hud})}{\Prob(\textrm{färg})}
 \frac{\Prob(\textrm{färg}}{\Prob(\textrm{ickehud})\Prob(\textrm{ickehud}|\textrm{färg})}=\\
=\frac{\Prob(\textrm{färg}|\textrm{hud})\Prob(\textrm{hud})}{\Prob(\textrm{färg}|\textrm{ickehud})
 P(\textrm{ickehud})}
\end{multline*}
är större än ett, så sägs pixeln föreställa hud. Kvoten
$\Prob(\textrm{hud})/\Prob(\textrm{ickehud})$ sätts för att ange hur mycket vanligare
bildpunkter med ickehud är i bilderna, och måste sannolikt uppskattas i 
tillämpningar.

Sannolikheten är dock tidskrävande att räkna ut, varför beräkningen
är direkt olämplig att göra för varje bildpunkt i varje bild i en
filmsekvens. Detta löses genom att göra beräkningen en enda gång för
varje tänkbar färg ($256^2$ stycken i $C_bC_r$-rymden). Resultatet sparas
sedan i en $256\times256$-matris, där färgvärdet används som koordinater.
Denna matris, eller ''Skin Probability Map'', kan man sedan slå upp
färgvärden för att direkt få veta sannolikheten för att dessa är hud.

\subsubsection{Urskiljning av handen}

När väl hudpixlarna i figuren urskiljts återstår att plocka ut
vad som är handen som ska följas. Det är troligt att man bland
pixlarna fått med ett antal mindre områden som felaktigt bedömts vara
hud. Dessutom är ofta huvudet med i bilden, vilket kan ställa till med
problem. 

Vår lösning på problemet är att först använda den inbyggda
matlabfunktionen \texttt{bwareaopen}, som tar bort sammanhängande 
områden med för få pixlar. Vad som är en lagom gräns kan naturligtvis
variera, men vi använder en gräns på 200 pixlar, vilket visar sig
fungera väldigt bra. Därefter loopar vi igenom bildens kolonner från
höger för att se om kolonnen innehåller någon hudpixel. Den första
pixel som nås på detta sätt väljs till att tillhöra handen, och det
sammanhängande område som pixeln är en del av betraktas som den sökta
handen. Att på detta sätt välja objektet längst till höger av de
intressanta har tidigare gjorts av bl.a. \citeasnoun{Nielsen04}. De använde
sig dock av det högra av de två största sammanhängande objekten,
vilket har fördelen att man inte behöver sätta en manuell gräns för
när ett objekt är ''tillräckligt stort''. En nackdel är att man tvingas
söka igenom hela bilden, samt att den är något svårare att
implementera.

En alternativ metod för att leta från
vänster är lätt att implementera om man vill kunna använda programmet
som vänsterhänt, detta kommer dock att kräva en
separat inlärningsmängd till gestigenkänningen.

Metoden kommer på detta sätt plocka med all hud som hänger samman med
handen, inklusive armen om man använder programmet kortärmad. För att
råda bot på detta kan man identifiera handleden och kapa handen
där. Detta har gjorts av \citeasnoun{Deimel99}, och
görs genom att identifiera den största cirkel
som får plats helt i handen. Denna antas vara centrerad mitt i handen. Då
cirkeln förstoras något är det längsta cirkelsegment som helt får
plats i hudområdet placerat vid handleden, och mittpunktstangenten
till segmentet är då handleden. Handen utgörs då av hudområdet på den
sida om handleden som cirkeln befinner sig på. Denna metod har vi dock
inte implementerat, varför vi förutsätter att användaren använder
långärmad tröja. 

\subsubsection{Morfologiska operationer}

Morfologiska operationer kan användas för att modifiera ''objekt'' i
binära bilder, till exempel för att rensa bort brus eller för att
mjuka upp kanter. Det finns fyra grundläggande morfologiska
operationer: \emph{erosion}, \emph{dilatation}, \emph{öppning} och
\emph{stängning} \cite[ss.~25]{Rudemo09}.

Dessa definieras som operationer på mängder; specifikt mängden $A$
av alla svarta pixlar i bilden vi behandlar, dvs. alla pixlar som är
''avstängda'' och mängden $S$ som representerar ett strukturelement
som i någon mening förändrar hur operationen verkar på bilden.
Strukturelementet kan dessutom förflyttas så att dess referenspixel
ligger på plats $(i,j)$ i bilden --- kalla detta förflyttade
strukturelement för $S_{i,j}$.

\emph{Erosionen}, som eroderar bort delar av de svarta områdena genom
att endast behålla de pixlar vars ''omgivning'' (definierad av mängden
$S_{i,j}$) ligger helt i mängden $A$. Vad operationen egentligen gör är alltså
att skala av det yttersta lagret, randen, av mängden $A$. Erosion definieras enligt
\begin{equation*}
  A\ominus S = \{(i,j)\;:\;S_{i,j}\subseteq A\}.
\end{equation*}

Dess motsats, \emph{dilatation}, agerar som
en erosion på komplementet till $A$ och definieras enligt
\begin{equation*}
  A\oplus S = (A^C\ominus S)^C.
\end{equation*}

Dessa operationer är i sig inte särskilt användbara då de förändrar
arean av objekten i bilderna. Operationerna kan dock kombineras för
att skapa operationer som i någon mening endast 
''mjukar upp'' objekten i bilden utan att förändra deras area markant.
Eftersom erosion och dilatation är motsatser kan dessa appliceras i
följd för att behandla bilden och
sedan återställa den. Detta ger upphov till två nya operationer:
\emph{öppning} och \emph{stängning}.

En öppning är en erosion följd av en dilatation, enligt
\begin{equation*}
  \phi_S(A)=(A\ominus S)\oplus S'.
\end{equation*}

Detta resulterar i att svart ''brus'', dvs.~svarta områden som inte kan täckas av $S$, försvinner i
första steget varefter större svarta områdena utökas igen i det andra
steget. Operationen ''öppnar upp'' vita områden.

En stängning består av motsatt procedur, enligt
\begin{equation*}
  \Phi_S(A)=(A\oplus S)\ominus S',
\end{equation*}
och ger även motsatt resultat (svarta områden ''öppnas upp'').

De
båda operationerna använder utöver $A$ och $S$ även $S'$, vilket är
$S$ roterad 180\textdegree{} runt sin referenspixel.

\end{document} 
